{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, \\\n",
    "                         RepeatVector, LSTM, concatenate, \\\n",
    "                         Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import array_to_img, \\\n",
    "                                      img_to_array, load_img\n",
    "from brainfart5 import chars_to_tokens, tokens_to_code\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_sizes = [32, 64, 128]\n",
    "kernel_sizes = [(3, 3), (3, 3), (3, 3)]\n",
    "pool_sizes = [(2, 2), (2, 2), (2, 2)]\n",
    "cnn_activation = 'relu'\n",
    "cnn_dropout = 0.25\n",
    "\n",
    "mlp_units = [1024, 1024]\n",
    "mlp_activation = 'relu'\n",
    "mlp_dropout = 0.3\n",
    "\n",
    "text_rnn_sizes = [128, 128]\n",
    "text_rnn_dropout = 0.0\n",
    "\n",
    "decoder_sizes = [512, 512]\n",
    "decoder_dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = 15\n",
    "learning_rate = 0.0001\n",
    "\n",
    "max_dataset_size = 600 #-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "START_TOKEN = '<start_token>'\n",
    "END_TOKEN = '<end_token>'\n",
    "PAD_TOKEN = '<pad_token>'\n",
    "\n",
    "\n",
    "def unison_shuffle(a, b, c):\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p], c[p]\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    image = load_img(path)\n",
    "    return img_to_array(image)\n",
    "\n",
    "\n",
    "def make_if_not_exist(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where all the data is.\n",
    "dataset_directory = 'size_60000_ln_len_7'\n",
    "\n",
    "# Where the image output is.\n",
    "image_directory = os.path.join(dataset_directory, 'images')\n",
    "\n",
    "# Where the corresponding chars are.\n",
    "tokens_directory = os.path.join(dataset_directory, 'tokens')\n",
    "\n",
    "# Dataset size. \n",
    "dataset_size = max_dataset_size if max_dataset_size > -1 \\\n",
    "               else len(os.listdir(image_directory))\n",
    "\n",
    "# Get the shape of the images we are working with.\n",
    "first_image_path = os.path.join(image_directory, 'output_0.png')\n",
    "first_image_shape = load_image(first_image_path).shape\n",
    "\n",
    "# Create a container to hold all of the images.\n",
    "all_images = np.zeros((dataset_size, *first_image_shape))\n",
    "\n",
    "all_chars_list = [[START_TOKEN, END_TOKEN, PAD_TOKEN]]\n",
    "\n",
    "# Load all the images into the container.\n",
    "for i in range(dataset_size):\n",
    "    \n",
    "    image_name = 'output_{}.png'.format(i)\n",
    "    image_path = os.path.join(image_directory, image_name)\n",
    "    all_images[i] = load_image(image_path) / 255.0\n",
    "    \n",
    "    tokens_name = 'tokens_{}.bf5'.format(i)\n",
    "    \n",
    "    with open(os.path.join(tokens_directory, tokens_name)) as file:\n",
    "        chars = list(file.read())\n",
    "        all_chars_list.append(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'd', '}', '\"', 'l', '%', ')', '1', 'q', 'V', '$', 'n', 'h', 'O', ',', '8', '&', '.', '@', 'w', '<', 'k', 'B', 'v', 'j', '9', '!', '6', 'u', '7', 'e', 'F', '_', '|', '*', '<end_token>', 'm', 'W', 'T', '\\\\', 's', 'f', '^', '+', ';', 'y', '<pad_token>', 'G', 'x', 'E', 'i', 'o', 'c', 'J', 'I', 'H', 'U', '-', 'X', 'g', 'K', '{', '>', 'S', 'z', '[', 'Y', \"'\", '#', '(', 'a', '?', '0', '5', 'P', '/', 'Q', 't', 'N', '=', 'A', '`', 'D', ']', 'R', 'r', 'L', '<start_token>', 'C', '4', 'b', 'Z', '~', ':', '3', '2', 'M'] \n",
      "\n",
      "\n",
      " {'p': 0, 'd': 1, '}': 2, '\"': 3, 'l': 4, '%': 5, ')': 6, '1': 7, 'r': 85, 'H': 55, '$': 10, 'n': 11, 'h': 12, 'O': 13, ',': 14, '&': 16, '.': 17, '@': 18, 'w': 19, 'k': 21, 'B': 22, 'v': 23, 'j': 24, '9': 25, '!': 26, '6': 27, 'u': 28, '7': 29, 'e': 30, '>': 62, '_': 32, '|': 33, '<end_token>': 35, 'm': 36, 'W': 37, 'T': 38, '\\\\': 39, 's': 40, '=': 79, '^': 42, '+': 43, ';': 44, 'y': 45, '<pad_token>': 46, 'G': 47, 'x': 48, 'L': 86, 'E': 49, 'i': 50, 'o': 51, 'c': 52, 'I': 54, 'C': 88, 'V': 9, 'U': 56, '-': 57, 'X': 58, '8': 15, 'K': 60, '{': 61, 'F': 31, 'S': 63, 'z': 64, '[': 65, 'Y': 66, \"'\": 67, '#': 68, '(': 69, 'a': 70, '?': 71, '0': 72, '5': 73, 'P': 74, '/': 75, 'Q': 76, 't': 77, 'M': 96, 'A': 80, '`': 81, 'D': 82, 'g': 59, ']': 83, 'R': 84, 'q': 8, 'f': 41, '*': 34, '<start_token>': 87, 'J': 53, '4': 89, 'b': 90, 'N': 78, 'Z': 91, '~': 92, ':': 93, '3': 94, '2': 95, '<': 20}\n"
     ]
    }
   ],
   "source": [
    "all_chars_dict = dict()\n",
    "\n",
    "for char_list in all_chars_list:\n",
    "    \n",
    "    for char in char_list:\n",
    "        \n",
    "        try:\n",
    "            all_chars_dict[char] += 1\n",
    "        except:\n",
    "            all_chars_dict[char] = 0\n",
    "\n",
    "# These are the chars that are used.\n",
    "len(all_chars_dict)\n",
    "\n",
    "tokens_to_chars = list()\n",
    "chars_to_tokens = dict()\n",
    "counter = 0\n",
    "\n",
    "for key, value in all_chars_dict.items():\n",
    "    tokens_to_chars.append(key)\n",
    "    chars_to_tokens[key] = counter\n",
    "    counter += 1\n",
    "    \n",
    "print(tokens_to_chars, '\\n\\n\\n', chars_to_tokens)\n",
    "\n",
    "output_size = len(tokens_to_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_tokens = [PAD_TOKEN for _ in range(sequence_length)]\n",
    "\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "for i in range(dataset_size):\n",
    "    \n",
    "    tokens_name = 'tokens_{}.bf5'.format(i)\n",
    "    \n",
    "    with open(os.path.join(tokens_directory, tokens_name)) as file:\n",
    "        chars = list(file.read())\n",
    "        \n",
    "        char_sequence = pad_tokens + [START_TOKEN] + chars + [END_TOKEN]\n",
    "        tokens = [chars_to_tokens[c] for c in char_sequence]\n",
    "        \n",
    "    sequence_one_hot = to_categorical(tokens, num_classes=output_size)\n",
    "    images = [all_images[i] for _ in range(sequence_length)]\n",
    "    \n",
    "    for start in range(len(sequence_one_hot) - sequence_length):\n",
    "        \n",
    "        end = start + sequence_length\n",
    "        data_x.append([images, sequence_one_hot[start:end]])\n",
    "        data_y.append(sequence_one_hot[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_hyper_params = list(zip(range(len(filter_sizes)), filter_sizes, kernel_sizes, pool_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "image_model = Sequential()\n",
    "image_shape = (100, 100, 3)\n",
    "\n",
    "for layer, filters, kernel_size, pool_size in cnn_hyper_params:\n",
    "    if layer == 0:\n",
    "        image_model.add(Conv2D(filters, \n",
    "                               kernel_size, \n",
    "                               padding='valid', \n",
    "                               activation=cnn_activation, \n",
    "                               input_shape=image_shape))\n",
    "    else:\n",
    "        image_model.add(Conv2D(filters, \n",
    "                               kernel_size, \n",
    "                               padding='valid',\n",
    "                               activation=cnn_activation))\n",
    "    image_model.add(Conv2D(filters, kernel_size, \n",
    "                           padding='valid',\n",
    "                           activation=cnn_activation))\n",
    "    image_model.add(MaxPooling2D(pool_size))\n",
    "    image_model.add(Dropout(cnn_dropout))\n",
    "\n",
    "image_model.add(Flatten())\n",
    "    \n",
    "for units in mlp_units:\n",
    "    image_model.add(Dense(units, activation=mlp_activation))\n",
    "    image_model.add(Dropout(mlp_dropout))\n",
    "\n",
    "image_model.add(RepeatVector(sequence_length))\n",
    "    \n",
    "image_input = Input(shape=image_shape)\n",
    "encoded_image = image_model(image_input)   \n",
    "\n",
    "\n",
    "text_shape = (sequence_length, output_size)\n",
    "text_model = Sequential()\n",
    "\n",
    "for layer, size in enumerate(text_rnn_sizes):\n",
    "    if layer == 0:\n",
    "        text_model.add(LSTM(size, return_sequences=True, \n",
    "                            recurrent_dropout=text_rnn_dropout,\n",
    "                            input_shape=text_shape))\n",
    "    else:\n",
    "        text_model.add(LSTM(size, return_sequences=True,\n",
    "                            recurrent_dropout=text_rnn_dropout))\n",
    "\n",
    "text_input = Input(shape=text_shape)\n",
    "encoded_text = text_model(text_input)\n",
    "\n",
    "decoder = concatenate([encoded_image, encoded_text])\n",
    "\n",
    "for layer, size in enumerate(decoder_sizes):\n",
    "    decoder = LSTM(size, \n",
    "                   recurrent_dropout=decoder_dropout,\n",
    "                   return_sequences=(layer != (len(decoder_sizes) - 1)))(decoder)\n",
    "decoder = Dense(output_size, activation='softmax')(decoder)\n",
    "                       \n",
    "model = Model(inputs=[image_input, text_input], outputs=decoder)\n",
    "optimiser = RMSprop(lr=learning_rate, clipvalue=1.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-ad67c8888df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1378\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     94\u001b[0m                         \u001b[0;34m' Numpy arrays instead. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                         \u001b[0;34m'The list you passed was: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                         str(data)[:200])\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36marray_repr\u001b[0;34m(arr, max_line_width, precision, suppress_small)\u001b[0m\n\u001b[1;32m   1879\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m         lst = array2string(arr, max_line_width, precision, suppress_small,\n\u001b[0;32m-> 1881\u001b[0;31m                            ', ', class_name + \"(\")\n\u001b[0m\u001b[1;32m   1882\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# show zero-length shape unless it is (0,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1883\u001b[0m         \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"[], shape=%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         lst = _array2string(a, max_line_width, precision, suppress_small,\n\u001b[0;32m--> 523\u001b[0;31m                             separator, prefix, formatter=formatter)\n\u001b[0m\u001b[1;32m    524\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, formatter)\u001b[0m\n\u001b[1;32m    362\u001b[0m     lst = _formatArray(a, format_function, a.ndim, max_line_width,\n\u001b[1;32m    363\u001b[0m                        \u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                        _summaryEdgeItems, summary_insert)[:-1]\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_formatArray\u001b[0;34m(a, format_function, rank, max_line_len, next_line_prefix, separator, edge_items, summary_insert)\u001b[0m\n\u001b[1;32m    580\u001b[0m             s += _formatArray(a[i], format_function, rank-1, max_line_len,\n\u001b[1;32m    581\u001b[0m                               \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_items\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                               summary_insert)\n\u001b[0m\u001b[1;32m    583\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_formatArray\u001b[0;34m(a, format_function, rank, max_line_len, next_line_prefix, separator, edge_items, summary_insert)\u001b[0m\n\u001b[1;32m    580\u001b[0m             s += _formatArray(a[i], format_function, rank-1, max_line_len,\n\u001b[1;32m    581\u001b[0m                               \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_items\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                               summary_insert)\n\u001b[0m\u001b[1;32m    583\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_formatArray\u001b[0;34m(a, format_function, rank, max_line_len, next_line_prefix, separator, edge_items, summary_insert)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrailing_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m             \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extendLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_line_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, strip_zeros)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_nc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_fmt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'+'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_nan_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "epochs = 20\n",
    "\n",
    "model.fit(x=data_x, \n",
    "          y=data_y, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs, \n",
    "          shuffle=True, \n",
    "          validation_split=0.1,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
